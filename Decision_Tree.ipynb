{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiksha-Yadav/WOC/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Normalization of dataset to ensure equal contribution of each feature\n",
        "def normalizationx(df, min=None, max=None):\n",
        "    if isinstance(df, pd.DataFrame):\n",
        "      min_val = df.min().min() if min is None else min\n",
        "      max_val = df.max().max() if max is None else max\n",
        "    elif isinstance(df, np.ndarray):\n",
        "      min_val = df.min() if min is None else min\n",
        "      max_val = df.max() if max is None else max\n",
        "\n",
        "    norm_df = (df - min_val) / (max_val - min_val)\n",
        "    return norm_df, min_val, max_val\n",
        "\n",
        "\n",
        "def normalizationy(df, min=None, max=None):\n",
        "    min = df.min() if min is None else min\n",
        "    max = df.max() if max is None else max\n",
        "    norm_df = (df - min) / (max - min)\n",
        "    return norm_df, min, max\n",
        "\n",
        "\n",
        "# Denormalize to get values for test dataset\n",
        "def denorm(normal_df, max_val, min_val):\n",
        "    return (normal_df * (max_val - min_val) + min_val)\n",
        "\n",
        "\n",
        "# Separate training and testing data\n",
        "def matrix(df):\n",
        "    x = df.iloc[1:, 1:-1].values  # all columns (features) except the last one (target)\n",
        "    y = df.iloc[1:, -1].values  # last column (target)\n",
        "    test_size = 0.2\n",
        "    rows = x.shape[0]\n",
        "    train_size = int(rows * (1 - test_size))\n",
        "    x_train = x[:train_size]  # First 80% for training\n",
        "    x_test = x[train_size:]  # Remaining 20% for testing\n",
        "    y_train = y[:train_size]  # First 80% of target for training\n",
        "    y_test = y[train_size:]  # Remaining 20% of target for testing\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "\n",
        "def find_gini(y):\n",
        "    count = np.bincount(y)\n",
        "    probabilities = count / len(y)\n",
        "    gini = 1 - np.sum(probabilities**2)\n",
        "    return gini\n",
        "\n",
        "\n",
        "def best_split(x, y):\n",
        "    best_gini = float(\"inf\")\n",
        "    best_split_ = None\n",
        "    n_samples, n_features = x.shape\n",
        "    for feature_index in range(n_features):\n",
        "        feature_values = x[:, feature_index]\n",
        "        thresholds = np.unique(feature_values)\n",
        "        for threshold in thresholds:\n",
        "            left_mask = feature_values <= threshold\n",
        "            right_mask = ~left_mask\n",
        "            left_y = y[left_mask]\n",
        "            right_y = y[right_mask]\n",
        "            if len(left_y) == 0 or len(right_y) == 0:\n",
        "                continue\n",
        "            gini_left = find_gini(left_y)\n",
        "            gini_right = find_gini(right_y)\n",
        "            weighted_gini = (len(left_y) / n_samples) * gini_left + (\n",
        "                len(right_y) / n_samples\n",
        "            ) * gini_right\n",
        "            if weighted_gini < best_gini:\n",
        "                best_gini = weighted_gini\n",
        "                best_split_ = {\n",
        "                    \"feature_index\": feature_index,\n",
        "                    \"threshold\": threshold,\n",
        "                    \"left_data\": (x[left_mask], left_y),\n",
        "                    \"right_data\": (x[right_mask], right_y),\n",
        "                }\n",
        "    return best_split_\n",
        "\n",
        "\n",
        "def tree(x, y, max_depth=None, depth=0):\n",
        "    n_samples, n_features = x.shape\n",
        "    unique_classes = np.unique(y)\n",
        "    if len(unique_classes) == 1:\n",
        "        return unique_classes[0]\n",
        "    if max_depth is not None and depth >= max_depth:\n",
        "        return np.bincount(y).argmax()\n",
        "    best_split_ = best_split(x, y)\n",
        "    if best_split_ is None:\n",
        "        return np.bincount(y).argmax()\n",
        "    left_tree = tree(\n",
        "        best_split_[\"left_data\"][0],\n",
        "        best_split_[\"left_data\"][1],\n",
        "        max_depth,\n",
        "        depth + 1,\n",
        "    )\n",
        "    right_tree = tree(\n",
        "        best_split_[\"right_data\"][0],\n",
        "        best_split_[\"right_data\"][1],\n",
        "        max_depth,\n",
        "        depth + 1,\n",
        "    )\n",
        "    return {\n",
        "        \"feature_index\": best_split_[\"feature_index\"],\n",
        "        \"threshold\": best_split_[\"threshold\"],\n",
        "        \"left\": left_tree,\n",
        "        \"right\": right_tree,\n",
        "    }\n",
        "\n",
        "\n",
        "def predict_row(row, tree):\n",
        "    if isinstance(tree, dict):\n",
        "        feature_value = row[tree[\"feature_index\"]]\n",
        "        if feature_value <= tree[\"threshold\"]:\n",
        "            return predict_row(row, tree[\"left\"])\n",
        "        else:\n",
        "            return predict_row(row, tree[\"right\"])\n",
        "    else:\n",
        "        return tree\n",
        "\n",
        "\n",
        "def predict(x, tree):\n",
        "    # Iterate directly over the rows of the NumPy array\n",
        "    return [predict_row(row, tree) for row in x]\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred, num_classes):\n",
        "    precision = np.zeros(num_classes)\n",
        "    recall = np.zeros(num_classes)\n",
        "    f1 = np.zeros(num_classes)\n",
        "    for i in range(num_classes):\n",
        "        tp = np.sum((y_pred == i) & (y_true == i))\n",
        "        fp = np.sum((y_pred == i) & (y_true != i))\n",
        "        fn = np.sum((y_pred != i) & (y_true == i))\n",
        "        precision[i] = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "        recall[i] = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "        f1[i] = (\n",
        "            2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
        "            if (precision[i] + recall[i]) != 0\n",
        "            else 0\n",
        "        )\n",
        "    return np.mean(f1)\n",
        "\n",
        "\n",
        "def plot_tree(tree, feature_names, depth=0):\n",
        "    if isinstance(tree, dict):\n",
        "        feature_name = feature_names[tree[\"feature_index\"]]\n",
        "        threshold = tree[\"threshold\"]\n",
        "        print(f\"{'|  ' * depth}Feature: {feature_name} <= {threshold:.2f}\")\n",
        "        print(f\"{'|  ' * depth}Left branch:\")\n",
        "        plot_tree(tree[\"left\"], feature_names, depth + 1)\n",
        "        print(f\"{'|  ' * depth}Right branch:\")\n",
        "        plot_tree(tree[\"right\"], feature_names, depth + 1)\n",
        "    else:\n",
        "        print(f\"{'|  ' * depth}Leaf: Class {tree}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = \"multi_classification_train.csv\"\n",
        "    df1 = pd.read_csv(dataset)  # dataset\n",
        "    x_train, x_test, y_train, y_test = matrix(df1)\n",
        "    x_train_norm, min_x, max_x = normalizationx(x_train)\n",
        "    x_test_norm, _, _ = normalizationx(x_test, min_x, max_x)\n",
        "    # y_train_norm, min_y, max_y= normalizationy(y_train)\n",
        "    # y_test_norm, _, _= normalizationy(y_test, min_y, max_y)\n",
        "    tree_ = tree(x_train_norm, y_train, max_depth=3)\n",
        "    y_pred = predict(x_test_norm, tree_)\n",
        "    accuracy = np.mean(np.array(y_pred) == y_test)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nDecision Tree Structure:\")\n",
        "    plot_tree(tree_, df1.columns[1:-1])\n",
        "    num_classes = len(np.unique(y_train))  # Number of unique classes in target\n",
        "    f1 = f1_score(y_test, y_pred, num_classes)\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmhj9oiU2JI8",
        "outputId": "40df0362-2350-4667-c5ae-f04b1d07caa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6465\n",
            "\n",
            "Decision Tree Structure:\n",
            "Feature: Feature_11 <= 0.49\n",
            "Left branch:\n",
            "|  Feature: Feature_17 <= 0.42\n",
            "|  Left branch:\n",
            "|  |  Feature: Feature_10 <= 0.33\n",
            "|  |  Left branch:\n",
            "|  |  |  Leaf: Class 3\n",
            "|  |  Right branch:\n",
            "|  |  |  Leaf: Class 2\n",
            "|  Right branch:\n",
            "|  |  Feature: Feature_10 <= 0.46\n",
            "|  |  Left branch:\n",
            "|  |  |  Leaf: Class 3\n",
            "|  |  Right branch:\n",
            "|  |  |  Leaf: Class 2\n",
            "Right branch:\n",
            "|  Feature: Feature_2 <= 0.45\n",
            "|  Left branch:\n",
            "|  |  Feature: Feature_3 <= 0.52\n",
            "|  |  Left branch:\n",
            "|  |  |  Leaf: Class 4\n",
            "|  |  Right branch:\n",
            "|  |  |  Leaf: Class 3\n",
            "|  Right branch:\n",
            "|  |  Feature: Feature_14 <= 0.36\n",
            "|  |  Left branch:\n",
            "|  |  |  Leaf: Class 3\n",
            "|  |  Right branch:\n",
            "|  |  |  Leaf: Class 1\n",
            "F1 Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmZX3BlwBEiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Zx5x4sOGI3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}